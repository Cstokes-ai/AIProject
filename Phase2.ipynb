{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-16T16:56:07.150477Z",
     "start_time": "2025-04-16T16:56:02.679521Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import keras"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T16:35:05.897364Z",
     "start_time": "2025-04-16T16:35:05.675660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Load the dataset for phase 2\n",
    "#first I need the path\n",
    "data_set = \"C:\\\\Users\\corne\\Downloads\\loan_data.csv\"\n",
    "df = pd.read_csv(data_set)\n",
    "print(df.head())\n"
   ],
   "id": "776ad9ff9b32c19",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\corne\\AppData\\Local\\Temp\\ipykernel_6036\\1115940107.py:3: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  data_set = \"C:\\\\Users\\corne\\Downloads\\loan_data.csv\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   person_age person_gender person_education  person_income  person_emp_exp  \\\n",
      "0        22.0        female           Master        71948.0               0   \n",
      "1        21.0        female      High School        12282.0               0   \n",
      "2        25.0        female      High School        12438.0               3   \n",
      "3        23.0        female         Bachelor        79753.0               0   \n",
      "4        24.0          male           Master        66135.0               1   \n",
      "\n",
      "  person_home_ownership  loan_amnt loan_intent  loan_int_rate  \\\n",
      "0                  RENT    35000.0    PERSONAL          16.02   \n",
      "1                   OWN     1000.0   EDUCATION          11.14   \n",
      "2              MORTGAGE     5500.0     MEDICAL          12.87   \n",
      "3                  RENT    35000.0     MEDICAL          15.23   \n",
      "4                  RENT    35000.0     MEDICAL          14.27   \n",
      "\n",
      "   loan_percent_income  cb_person_cred_hist_length  credit_score  \\\n",
      "0                 0.49                         3.0           561   \n",
      "1                 0.08                         2.0           504   \n",
      "2                 0.44                         3.0           635   \n",
      "3                 0.44                         2.0           675   \n",
      "4                 0.53                         4.0           586   \n",
      "\n",
      "  previous_loan_defaults_on_file  loan_status  \n",
      "0                             No            1  \n",
      "1                            Yes            0  \n",
      "2                             No            1  \n",
      "3                             No            1  \n",
      "4                             No            1  \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Now, we must exclude all of the colums i dropped in phase 1.\n",
    "#keep all of the number columns\n",
    "#drop the columns that are not needed\n",
    "featrues_drop = df.drop(columns=['person_gender', 'person_home_ownership', 'loan_intent', 'previous_loan_defaults_on_file','person_education'])\n",
    "\n",
    "#Separate the loan_status column (your target y) from the rest of the features.\n",
    "\n",
    "#Normalize/scale the remaining numerical features (X).\n",
    "\n",
    "#Split your data into training and testing sets.\n",
    "\n",
    "#first lets seperate loan status\n",
    "y = df['loan_status']\n",
    "#normaliz/scalr the remaining\n",
    "scale = StandardScaler()\n",
    "#now split the data for training and tests\n",
    "#im still using keras and tensorflow for this\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = scale.fit_transform(featrues_drop)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#now this is where i use tensorflow and keras\n",
    "\n"
   ],
   "id": "d612f5c05eae9b63"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
